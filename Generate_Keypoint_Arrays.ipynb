{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd407091",
   "metadata": {},
   "source": [
    "# Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6692de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46d22c",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65020a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Holistic object to detect pose, face, and hands keypoints\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e159266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "  \"\"\" Takes an input image and a MediaPipe model, and applies the model to the \n",
    "  image using the MediaPipe library for object detection or pose estimation.\n",
    "  Args:\n",
    "    image(numpy.ndarray): a frame of our video\n",
    "    model(mediapipe.python.solutions.holistic.Holistic): the mediapipe model of choice\n",
    "  Returns:\n",
    "    image(numpy.ndarray): The processed image in BGR format. It can be used to display the input image with any detected objects\n",
    "    or keypoints overlaid on top.\n",
    "    results(mediapipe.python.solution_base.SolutionOutputs): contains the detected landmarks for the face, pose, left hand and \n",
    "    right hand in an image or a video frame.\n",
    "  \"\"\"\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "  image.flags.writeable = False                  # Image is no longer writeable\n",
    "  results = model.process(image)                 # Make prediction\n",
    "  image.flags.writeable = True                   # Image is now writeable \n",
    "  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "  return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c62b9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_landmarks(arr,center):\n",
    "    \"\"\"\n",
    "    Adjusts the array to make the landmarks in the array relative to the center.\n",
    "    Args:\n",
    "        arr (numpy.ndarray): The input array of landmarks with shape (n*3,).\n",
    "        center (numpy.ndarray): The center array with shape (3,) to be subtracted from arr.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The adjusted array of landmarks with shape (n*3,).\n",
    "\n",
    "    \"\"\"\n",
    "    # Reshape the array to have shape (n, 3)\n",
    "    arr_reshaped = arr.reshape(-1, 3)\n",
    "\n",
    "    # Repeat the center array to have shape (n, 3)\n",
    "    center_repeated = np.tile(center, (len(arr_reshaped), 1))\n",
    "\n",
    "    # Subtract the center array from the arr array\n",
    "    arr_adjusted = arr_reshaped - center_repeated\n",
    "\n",
    "    # Reshape arr_adjusted back to shape (n*3,)\n",
    "    arr_adjusted = arr_adjusted.reshape(-1)\n",
    "    return(arr_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e09afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    \"\"\"\n",
    "    Extracts keypoints from the input results object and adjusts them to make them relative to specific landmarks.\n",
    "\n",
    "    Args:\n",
    "        results: The results object containing pose and hand landmarks.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the adjusted pose keypoints, left hand keypoints, and right hand keypoints.\n",
    "        \n",
    "    Note:\n",
    "        - The pose keypoints are represented as a numpy.ndarray with shape (33*3,).\n",
    "        - The left hand keypoints are represented as a numpy.ndarray with shape (21*3,).\n",
    "        - The right hand keypoints are represented as a numpy.ndarray with shape (21*3,).\n",
    "    \"\"\"\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    nose=pose[:3]\n",
    "    lh_wrist=lh[:3]\n",
    "    rh_wrist=rh[:3]\n",
    "    pose_adjusted = adjust_landmarks(pose,nose)\n",
    "    lh_adjusted = adjust_landmarks(lh,lh_wrist)\n",
    "    rh_adjusted = adjust_landmarks(rh,rh_wrist)\n",
    "    return pose_adjusted, lh_adjusted, rh_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93ab7f",
   "metadata": {},
   "source": [
    "# Make keypoint arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8809d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keypoint_arrays(signer,split):\n",
    "    \"\"\"This function generates numpy arrays of keypoints for each video in the specified folder location.\n",
    "    Args:\n",
    "      signer(int): the signer of interest. Could be 1 or 2 or 3\n",
    "      split(str): can be 'train', 'test' or 'val'\n",
    "    \"\"\"\n",
    "    words_folder = os.path.join(str(signer), split)\n",
    "    \n",
    "    # Loop through all the subfolders in the folder\n",
    "    for word in tqdm(os.listdir(words_folder)):\n",
    "          video_files = os.listdir(os.path.join(words_folder, word))\n",
    "          video_files = [v for v in video_files if v.endswith('.mp4')]\n",
    "          # Loop through the video files\n",
    "          for video_file in video_files:\n",
    "                  if os.path.isfile(os.path.join(words_folder, word,'pose_keypoints', f'{video_file[:-4]}.npy')) and os.path.isfile(os.path.join(words_folder, word,'lh_keypoints', f'{video_file[:-4]}.npy')) and os.path.isfile(os.path.join(words_folder, word,'rh_keypoints', f'{video_file[:-4]}.npy')):\n",
    "                      pass\n",
    "                  else:\n",
    "                      # Open the video file\n",
    "                      video = cv2.VideoCapture(os.path.join(words_folder, word, video_file))\n",
    "    \n",
    "                      # Check if the video file was successfully opened\n",
    "                      if not video.isOpened():\n",
    "                          print(f'Could not open video file {video_file}')\n",
    "                          continue\n",
    "    \n",
    "                      # Initialize the list of keypoints for this video\n",
    "                      pose_keypoints, lh_keypoints, rh_keypoints = [], [], []\n",
    "    \n",
    "                      # Initialize the Mediapipe Holistic model\n",
    "                      with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                          # Loop through the video frames\n",
    "                          while True:\n",
    "                              # Read the next frame\n",
    "                              ret, frame = video.read()\n",
    "    \n",
    "                              # Check if there are no more frames to read\n",
    "                              if not ret:\n",
    "                                  break\n",
    "    \n",
    "                              # Make detections\n",
    "                              image, results = mediapipe_detection(frame, holistic)\n",
    "    \n",
    "                              # Extract keypoints\n",
    "                              pose, lh, rh = extract_keypoints(results)\n",
    "                              # Add the keypoints to the list for this video\n",
    "                              pose_keypoints.append(pose)\n",
    "                              lh_keypoints.append(lh)\n",
    "                              rh_keypoints.append(rh)\n",
    "            \n",
    "                      # Release the video file\n",
    "                      video.release()            \n",
    "                      # Save the keypoints for this video to a numpy array\n",
    "                      pose_directory = os.path.join(words_folder, word,'pose_keypoints')\n",
    "                      lh_directory = os.path.join(words_folder, word,'lh_keypoints')\n",
    "                      rh_directory = os.path.join(words_folder, word,'rh_keypoints')\n",
    "                    \n",
    "                      if not os.path.exists(pose_directory):\n",
    "                        os.makedirs(pose_directory)\n",
    "                        \n",
    "                      if not os.path.exists(lh_directory):\n",
    "                        os.makedirs(lh_directory)\n",
    "                        \n",
    "                      if not os.path.exists(rh_directory):\n",
    "                        os.makedirs(rh_directory)\n",
    "                        \n",
    "                      pose_path = os.path.join(pose_directory, video_file[:-4])\n",
    "                      np.save(pose_path, pose_keypoints)\n",
    "                        \n",
    "                      lh_path = os.path.join(lh_directory, video_file[:-4])\n",
    "                      np.save(lh_path, lh_keypoints)\n",
    "                        \n",
    "                      rh_path = os.path.join(rh_directory, video_file[:-4])\n",
    "                      np.save(rh_path, rh_keypoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
